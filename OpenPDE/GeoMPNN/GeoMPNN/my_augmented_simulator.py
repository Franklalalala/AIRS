import random
import datetime as dt
from tqdm import tqdm
import numpy as np
import os
from typing import Dict, Union

from lips.benchmark.airfransBenchmark import AirfRANSBenchmark
from lips.dataset.airfransDataSet import AirfRANSDataSet
from lips.dataset.scaler.standard_scaler_iterative import StandardScalerIterative

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.tensorboard import SummaryWriter

from torch_geometric.loader import DataLoader
from torch_geometric.data import Data
from torch_geometric.utils import scatter, degree
from torch_geometric.transforms import RadiusGraph
from torch_geometric.nn.norm.instance_norm import InstanceNorm

import numpy as np
import math

VOLUME = 'volume'
SURFACE = 'surface'
SURFACE2VOLUME = 'surf2vol'

NOSE = "nose"
TAIL = "tail"
CLOSEST = "closest"

INLET = "inlet"
NORMAL = "normal"

CANONICAL_COORDS = "canonical_coords"
INLET_COORDS = "inlet_coords"

DIST = "dist"
ANGLE = "angle"
COORD = "coord"

def change_basis(coords, basis, eps=1e-12):
    numpy = False
    if isinstance(coords, np.ndarray):
        numpy = True
        coords = torch.from_numpy(coords)
    if isinstance(basis, np.ndarray):
        basis = torch.from_numpy(basis)
    assert basis.ndim == 1 and len(basis) == 2, basis.shape
    coords = coords / (basis.norm(dim=-1) + eps)
    y_proj = torch.stack([-basis[1], basis[0]])
    proj = torch.stack([basis, y_proj], dim=1)
    coords = coords.mm(proj)
    if numpy:
        coords = coords.numpy()
    return coords

class RadGr(torch.nn.Module):
    def __init__(self, r, max_num_neighbors):
        super(RadGr, self).__init__()
        self.r = r
        self.max_num_neighbors = max_num_neighbors
    
    def forward(self, data: Data):
        with torch.no_grad():
            data = data.clone()
            if self.r == 0:
                data.edge_index = torch.tensor([[], []], device=data.pos.device, dtype=torch.long)
                return data
            N = len(data.pos)
            dists = (data.pos.unsqueeze(0) - data.pos.unsqueeze(1)).norm(dim=-1)
            dists = dists + torch.diag(torch.ones(len(dists), device=dists.device) * self.r)
            max_neighb = (dists < self.r).sum(dim=1).max().item()
            source_dists, source_inds = dists.neg().topk(k=max_neighb, dim=1)
            source_dists = source_dists.neg()
            neighb_sizes = (source_dists < self.r).sum(dim=1)
            sample_inds = torch.zeros(N, self.max_num_neighbors, device=dists.device, dtype=torch.long)
            for neighb_size in neighb_sizes.unique():
                neighb_mask = neighb_sizes == neighb_size
                num_size = neighb_mask.sum()
                if neighb_size <= self.max_num_neighbors:
                    sample_inds[neighb_mask] = torch.arange(self.max_num_neighbors, device=dists.device).repeat(num_size, 1)
                else:
                    sample_inds[neighb_mask] = torch.rand(num_size, neighb_size, device=dists.device).argsort(dim=-1)[:, :self.max_num_neighbors]
            sample_inds = sample_inds.repeat(2, 1, 1)
            source_dists, source_inds = torch.stack([source_dists, source_inds]).gather(dim=-1, index=sample_inds)
            target_inds = torch.arange(N, device=dists.device).repeat_interleave(self.max_num_neighbors)
            edge_inds = torch.stack([source_inds.flatten(), target_inds]).long()
            mask = source_dists.flatten() < self.r
            edge_inds = edge_inds[:, mask]

            # correctness
            sc, targ = edge_inds
            assert degree(targ).equal(neighb_sizes.clamp(max=self.max_num_neighbors))
            assert ((data.pos[sc] - data.pos[targ]).norm(dim=-1) < self.r).all()

            data.edge_index = edge_inds
            return data
        
def get_radius_fn(manual: bool):
    if manual:
        radius_fn = RadGr
    else:
        try:
            radius_fn = RadiusGraph
            radius_fn(r=0)(data=Data(pos=torch.zeros(1)))
        except ImportError as e:
            radius_fn = RadGr
    return radius_fn
    
class SphericalHarmonicsEmbedding(torch.nn.Module):
    def __init__(self, num_spherical):
        super().__init__()
        coefs = [
            [0.282094791773878, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, 0.48860251190292, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [-0.31539156525252, 0, 0.94617469575756, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, -1.11952899777035, 0, 1.86588166295058, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0.317356640745613, 0, -3.17356640745613, 0, 3.70249414203215, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, 1.75425483680135, 0, -8.18652257173965, 0, 7.36787031456569, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [-0.317846011338142, 0, 6.67476623810098, 0, -20.024298714303, 0, 14.6844857238222, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, -2.38994969192017, 0, 21.5095472272816, 0, -47.3210039000194, 0, 29.2939547952501, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0.318036967204775, 0, -11.4493308193719, 0, 62.9713195065454, 0, -109.150287144679, 0, 58.4733681132208, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, 3.02602458828178, 0, -44.3816939614661, 0, 173.088606449718, 0, -247.269437785311, 0, 116.766123398619, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [-0.318130493737367, 0, 17.4971771555552, 0, -151.642202014812, 0, 454.926606044435, 0, -552.410878768242, 0, 233.240148813258, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, -3.66228598750543, 0, 79.3495297292844, 0, -476.097178375706, 0, 1156.23600462672, 0, -1220.47133821709, 0, 465.998147319252, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0.318183090330888, 0, -24.8182810458093, 0, 310.228513072616, 0, -1406.36925926252, 0, 2862.96599207014, 0, -2672.1015925988, 0, 931.186918632914, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, 4.29865237278653, 0, -128.959571183596, 0, 1096.15635506056, 0, -3967.04204688585, 0, 6942.32358205024, 0, -5806.30699589657, 0, 1860.99583201813, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [-0.318215556336822, 0, 33.4126334153663, 0, -568.014768061228, 0, 3597.42686438778, 0, -10792.2805931633, 0, 16548.1635761838, 0, -12536.487557715, 0, 3719.61718745389, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, -4.93508359834131, 0, 195.758316067539, 0, -2231.64480316994, 0, 11158.2240158497, 0, -28515.4613738381, 0, 38884.7200552338, 0, -26920.1908074695, 0, 7435.10031825349, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0.318236987158568, 0, -43.2802302535653, 0, 959.378437287364, 0, -8058.77887321386, 0, 33098.5560864141, 0, -73552.3468586979, 0, 90268.7893265838, 0, -57533.9536367237, 0, 14862.9380228203, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, 5.57155763993023, 0, -282.292253756465, 0, 4149.69613022003, 0, -27269.4317128745, 0, 94685.5267808142, 0, -185927.943496872, 0, 207381.167746511, 0, -122453.641907463, 0, 29713.0160510757, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [-0.318251868824604, 0, 54.4210695690072, 0, -1523.7899479322, 0, 16355.345441139, 0, -87617.9220061017, 0, 262853.766018305, 0, -461985.406941263, 0, 472138.932368544, 0, -259676.412802699, 0, 59403.1009679377, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, -6.20806142012525, 0, 391.10786946789, 0, -7196.38479820918, 0, 59969.8733184099, 0, -269864.429932844, 0, 711460.769822953, 0, -1131040.19818008, 0, 1066409.32971265, 0, -548887.154999156, 0, 118765.056929642, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0.318262620395318, 0, -66.8351502830167, 0, 2305.81268476408, 0, -30744.1691301877, 0, 207523.141628767, 0, -802422.814297898, 0, 1884477.82145719, 0, -2733528.26848735, 0, 2391837.23492643, 0, -1156836.30970298, 0, 237455.874096927, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, 6.84458668912347, 0, -524.751646166133, 0, 11806.912038738, 0, -121442.523827019, 0, 684800.898246803, 0, -2315872.12861646, 0, 4898960.27207328, 0, -6531947.02943105, 0, 5331221.47255034, 0, -2431785.23309314, 0, 474777.116937231, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [-0.318270639408897, 0, 80.5224717704509, 0, -3355.10299043546, 0, 54352.6684450544, 0, -450350.681401879, 0, 2171691.06364906, 0, -6515073.19094719, 0, 12528986.9056677, 0, -15452417.1836568, 0, 11816554.316914, 0, -5099776.07361552, 0, 949308.966084274, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, -7.48112798737384, 0, 685.770065509269, 0, -18515.7917687503, 0, 230124.840554467, 0, -1585304.457153, 0, 6658278.72004259, 0, -17926135.0154993, 0, 31584142.6463559, 0, -36228869.5061141, 0, 26059362.2763277, 0, -10671929.3131628, 0, 1898169.24542421, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0.318276778829609, 0, -95.4830336488828, 0, 4726.4101656197, 0, -91377.2632019808, 0, 910509.158334023, 0, -5341653.72889294, 0, 19828866.1148298, 0, -48373717.3350794, 0, 78607290.669504, 0, -84258795.2274422, 0, 57207287.2860002, 0, -22288553.488052, 0, 3795514.54325524, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, 8.11768155885292, 0, -876.709608356115, 0, 27967.0365065601, 0, -412846.729382553, 0, 3405985.51740607, 0, -17339562.6340672, 0, 57576240.0285053, 0, -128312763.492098, 0, 193412621.440294, 0, -194543689.401933, 0, 125063800.329814, 0, -46466392.2174014, 0, 7589510.72884222, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [-0.318281583116179, 0, 111.716835673779, 0, -6479.57646907918, 0, 147302.3717304, 0, -1736063.66682257, 0, 12152445.667758, 0, -54501877.540248, 0, 163505632.620744, 0, -335186546.872525, 0, 471013775.016947, 0, -446223576.331845, 0, 272370234.903853, 0, -96711170.3644117, 0, 15176214.4264154, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, -8.75424473518041, 0, 1100.11675505434, 0, -40924.3432880214, 0, 707406.505407227, 0, -6877563.24701471, 0, 41640519.2955618, 0, -166562077.182247, 0, 455269677.631475, 0, -863673359.036181, 0, 1136412314.52129, 0, -1017359595.85716, 0, 591114073.482221, 0, -200978784.983955, 0, 30347223.9434462, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0.318285413012071, 0, -129.223877682901, 0, 8679.53711770151, 0, -229139.77990732, 0, 3150671.97372565, 0, -25905525.1172998, 0, 137770292.669276, 0, -496578637.313435, 0, 1245584748.59453, 0, -2198090732.81388, 0, 2718691169.53296, 0, -2306768265.05827, 0, 1278751973.02143, 0, -417069874.277759, 0, 60684770.0668697, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, 9.39081556874954, 0, -1358.53798561243, 0, 58281.2795827734, 0, -1165625.59165547, 0, 13178044.8834382, 0, -93444318.26438, 0, 442063505.635336, 0, -1448284247.03386, 0, 3354481895.70343, 0, -5531952599.93198, 0, 6453944699.92064, 0, -5203971220.48937, 0, 2758104746.85937, 0, -864363310.981568, 0, 121351499.324998, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [-0.318288515193961, 0, 148.004159565192, 0, -11396.3202865198, 0, 345688.382024433, 0, -5481630.05781602, 0, 52258206.5511794, 0, -324634313.423993, 0, 1380587684.56138, 0, -4141763053.68413, 0, 8906144082.75869, 0, -13781086107.0055, 0, 15212887260.9801, 0, -11685261229.4485, 0, 5932517239.56617, 0, -1789171865.90091, 0, 242669287.558974, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, -10.0273926048891, 0, 1654.5197798067, 0, -81071.4692105284, 0, 1856922.69953639, 0, -24139995.0939731, 0, 197947959.770579, 0, -1091251573.09422, 0, 4209113210.50627, 0, -11636960052.5762, 0, 23341972503.1206, 0, -34012588504.5472, 0, 35625833809.1107, 0, -26125611460.0145, 0, 12727861993.3404, 0, -3699230825.65066, 0, 485275441.644495, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0.318291062959405, 0, -168.057681242566, 0, 14705.0471087245, 0, -507814.293487953, 0, 9195065.95708543, 0, -100532721.130801, 0, 720484501.437405, 0, -3562835446.66849, 0, 12558994949.5064, 0, -32177294249.7158, 0, 60459442353.4134, 0, -83229881681.3223, 0, 82928324138.9986, 0, -58177408934.436, 0, 27241802596.2835, 0, -7640229693.67032, 0, 970432400.607319, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, 10.6639747352688, 0, -1990.60861725017, 0, 110478.778257385, 0, -2872448.234692, 0, 42528191.9191899, 0, -398991764.187309, 0, 2532063118.881, 0, -11333996817.8483, 0, 36752151446.111, 0, -87689343801.2472, 0, 154917840715.537, 0, -202066748759.396, 0, 191963411321.426, 0, -129069416159.135, 0, 58176608761.3837, 0, -15763984309.5362, 0, 1940642007.80276, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [-0.318293180939202, 0, 189.384442658825, 0, -18685.9316756708, 0, 728751.33535116, 0, -14939402.3746988, 0, 185580576.165703, 0, -1518386532.26484, 0, 8626437771.21892, 0, -35224620899.1439, 0, 105673862697.432, 0, -235819567282.69, 0, 393032612137.817, 0, -487018671562.077, 0, 442063101879.424, 0, -285352901742.274, 0, 123980915929.402, 0, -32494998126.6577, 0, 3880864303.89673, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, -11.3005611006599, 0, 2369.35097743836, 0, -147847.500992154, 0, 4329819.67191308, 0, -72404206.7358798, 0, 770117471.645267, 0, -5568541718.05039, 0, 28585180819.3253, 0, -107194428072.47, 0, 299016036202.153, 0, -626509790137.845, 0, 988052989189.724, 0, -1165902527243.87, 0, 1013106184642.11, 0, -628824528398.553, 0, 263700608683.264, 0, -66924018112.7981, 0, 7760936554.25726, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0.318294960619663, 0, -211.984443772696, 0, 23424.2810368829, 0, -1024421.89067968, 0, 23598289.9817283, 0, -330376059.744196, 0, 3058481401.57127, 0, -19762495210.1528, 0, 92389665107.4645, 0, -320042630764.419, 0, 833795274886.251, 0, -1645933529645.59, 0, 2462936767187.05, 0, -2773645713201.42, 0, 2311371427667.85, 0, -1381509359065.84, 0, 559845526556.924, 0, -137716011880.313, 0, 15520375942.067, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, 11.9371510247029, 0, -2793.29333978048, 0, 194692.545782699, 0, -6378498.64278557, 0, 119596849.55223, 0, -1430813218.2794, 0, 11684974615.9484, 0, -68106709190.0995, 0, 291957437189.912, 0, -939044388622.523, 0, 2293951292206.45, 0, -4279624545144.05, 0, 6091332269255.03, 0, -6559896289966.95, 0, 5251148507978.47, 0, -3026468387394.04, 0, 1186513174603.35, 0, -283167850073.404, 0, 31037917500.5382, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [-0.318296470382336, 0, 235.857684553311, 0, -29010.4952000573, 0, 1413778.13274946, 0, -36354294.8421289, 0, 569550619.193353, 0, -5919874617.67636, 0, 43130515071.6421, 0, -228591729879.703, 0, 903908474360.917, 0, -2711725423082.75, 0, 6233446751761.65, 0, -11021456575578.6, 0, 14955268768708.2, 0, -15430039205810.0, 0, 11882903756198.5, 0, -6612260961110.46, 0, 2510537584164.93, 0, -581807122679.493, 0, 62070461167.7979, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, -12.5737439677324, 0, 3264.98218362117, 0, -252709.621012278, 0, 9205850.479733, 0, -192299987.798867, 0, 2569827109.67577, 0, -23523802003.9551, 0, 154360948387.858, 0, -749104602470.487, 0, 2746716875725.12, 0, -7716966460370.57, 0, 16745512200567.0, 0, -28132460496952.5, 0, 36468004347901.4, 0, -36108713664670.9, 0, 26790335944755.8, 0, -14409953424830.8, 0, 5303831596702.42, 0, -1194556665923.97, 0, 124130719670.912, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0.318297762167338, 0, -261.004164977217, 0, 35540.0671310644, 0, -1919163.62507748, 0, 54764704.8727466, 0, -954122858.227408, 0, 11059151311.2722, 0, -90174618384.2197, 0, 537290434539.309, 0, -2402004295587.5, 0, 8204740988612.04, 0, -21666199147417.1, 0, 44509909118063.3, 0, -71215854588901.3, 0, 88360412175118.3, 0, -84094737104595.4, 0, 60188773532522.9, 0, -31328202979495.0, 0, 11188643921248.2, 0, -2450997388153.95, 0, 248242043159.182, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, 13.2103394939164, 0, -3786.96398825605, 0, 323785.420995892, 0, -13043926.9601202, 0, 301821976.605004, 0, -4477940598.35788, 0, 45640548406.3399, 0, -334697354979.826, 0, 1823608382647.43, 0, -7550378566750.78, 0, 24125257229951.3, 0, -60074751205017.1, 0, 117145764849783.0, 0, -178889259143829.0, 0, 212816532429727.0, 0, -194967403903363.0, 0, 134778603077135.0, 0, -67955598190152.3, 0, 23570184957845.6, 0, -5025761435006.22, 0, 496447166140.858, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [-0.318298875998156, 0, 287.423885026335, 0, -43113.5827539503, 0, 2566695.29328517, 0, -80850901.738483, 0, 1557727373.49477, 0, -20014436556.4177, 0, 181449562187.303, 0, -1206639588545.57, 0, 6048971009244.76, 0, -23304456730353.5, 0, 69913370191060.5, 0, -164651052986193.0, 0, 305491030617460.0, 0, -446113885981053.0, 0, 509697934097893.0, 0, -450096159546123.0, 0, 300866416808906.0, 0, -147090248217687.0, 0, 49588035316631.4, 0, -10299053488838.8, 0, 992823971630.224, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, -13.8469372474378, 0, 4361.7852329429, 0, -410007.811896633, 0, 18177012.9940841, 0, -463513831.349144, 0, 7593199309.91961, 0, -85666864009.3494, 0, 697573035504.702, 0, -4236730347991.79, 0, 19647527286301.1, 0, -70731098230684.1, 0, 199892234130194.0, 0, -446425989557433.0, 0, 789830596909305.0, 0, -1104984677449470.0, 0, 1214294989627270.0, 0, -1034910502523240.0, 0, 669647972220920.0, 0, -317730869702419.0, 0, 104195143505651.0, 0, -21093163197485.5, 0, 1985513700759.99, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0.318299843117725, 0, -315.116844686548, 0, 51836.7209509371, 0, -3386665.76879456, 0, 117202826.070069, 0, -2484699912.68546, 0, 35199915429.7107, 0, -352772778812.045, 0, 2601699243738.83, 0, -14521902968320.0, 0, 62597044900284.8, 0, -211366645117845.0, 0, 564410208158882.0, 0, -1198286288091170.0, 0, 2025674439392210.0, 0, -2719526143919650.0, 0, 2878530696689150.0, 0, -2370554691391070.0, 0, 1486300163649950.0, 0, -685008894768969.0, 0, 218675916407017.0, 0, -43176429488028.9, 0, 3970770999427.6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, 14.483536934942, 0, -4991.99239691001, 0, 513676.01764204, 0, -24949977.9997562, 0, 697906329.048737, 0, -12562313922.8773, 0, 156062592195.744, 0, -1403077019359.84, 0, 9439819652310.66, 0, -48689596101391.8, 0, 195917660503220.0, 0, -622599996223670.0, 0, 1575177990445880.0, 0, -3186257473551500.0, 0, 5156086601289010.0, 0, -6653014969405180.0, 0, 6791619447934450.0, 0, -5410466585413330.0, 0, 3290148599237830.0, 0, -1474128657148400.0, 0, 458418058015659.0, 0, -88333047723947.7, 0, 7941051765082.17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [-0.318300688202315, 0, 344.083043946702, 0, -61820.2535624242, 0, 4413966.10435709, 0, -167100145.379233, 0, 3880436709.36218, 0, -60323152481.903, 0, 664880460871.963, 0, -5407694415091.97, 0, 33400465504979.8, 0, -159970650576482.0, 0, 603179379446390.0, 0, -1809538138339170.0, 0, 4348459341670430.0, 0, -8397818305342370.0, 0, 1.30310973703589e+16, 0, -1.61837822180263e+16, 0, 1.59529974448637e+16, 0, -1.23065980288949e+16, 0, 7264919177797120.0, 0, -3166759641603870.0, 0, 959958497629049.0, 0, -180626440357263.0, 0, 15881165287450.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, -15.1201383124108, 0, 5680.13195936231, 0, -637310.805840451, 0, 33777472.7095439, 0, -1032089443.90273, 0, 20322779413.5756, 0, -276702458169.452, 0, 2732766182111.64, 0, -20254619938003.9, 0, 115486868067566.0, 0, -515841344035129.0, 0, 1828892037942730.0, 0, -5194053387757350.0, 0, 1.18826919383737e+16, 0, -2.19507856004439e+16, 0, 3.27137514432423e+16, 0, -3.91573691517597e+16, 0, 3.7314669426971e+16, 0, -2.79019600219693e+16, 0, 1.60031484606437e+16, 0, -6791580078419500.0, 0, 2008141617871550.0, 0, -369173509548103.0, 0, 31760533198865.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0.31830143095059, 0, -374.322482797894, 0, 73180.0453869882, 0, -5688528.86141522, 0, 234651815.533378, 0, -5944512660.1789, 0, 100966646849.402, 0, -1218256903743.34, 0, 10872942865909.3, 0, -73907585493762.5, 0, 390932228532796.0, 0, -1634807501137150.0, 0, 5467127983875320.0, 0, -1.47360126580762e+16, 0, 3.21619323886585e+16, 0, -5.69303171017633e+16, 0, 8.16077731035356e+16, 0, -9.42635240126401e+16, 0, 8.69319165894348e+16, 0, -6.30658285357208e+16, 0, 3.51713274526135e+16, 0, -1.4542383940918e+16, 0, 4196692194366410.0, 0, -754188162465847.0, 0, 63517620065829.3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, 15.7567411752111, 0, -6428.75039948613, 0, 783664.673697359, 0, -45154012.1511335, 0, 1501370904.02519, 0, -32211230304.5404, 0, 478625845166.184, 0, -5169159127794.79, 0, 41999417913332.7, 0, -263294596509314.0, 0, 1297666225653050.0, 0, -5098340823316710.0, 0, 1.61277514710919e+16, 0, -4.13532089002355e+16, 0, 8.62713496022155e+16, 0, -1.46568529431721e+17, 0, 2.02364503704024e+17, 0, -2.25831983965499e+17, 0, 2.01756802491699e+17, 0, -1.42128273820064e+17, 0, 7.71305876218637e+16, 0, -3.10913996615265e+16, 0, 8762121722793820.0, 0, -1540058397160800.0, 0, 127028626296427.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [-0.318302087241524, 0, 405.835161232943, 0, -86037.0541813838, 0, 7255791.5692967, 0, -324955808.139217, 0, 8947116584.09977, 0, -165386094433.359, 0, 2175463242161.88, 0, -21210766611078.3, 0, 157902373660250.0, 0, -917495897478504.0, 0, 4230013553309990.0, 0, -1.56633110560971e+16, 0, 4.69899331682914e+16, 0, -1.14864281078046e+17, 0, 2.29464506337521e+17, 0, -3.74730343010871e+17, 0, 4.98972488821962e+17, 0, -5.38573479998308e+17, 0, 4.66559387366955e+17, 0, -3.19413734428146e+17, 0, 1.68795875917313e+17, 0, -6.63763909526855e+16, 0, 1.82775569290003e+16, 0, -3143480535661410.0, 0, 254044549412636.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, -16.3933453504591, 0, 7240.39419645276, 0, -955732.033931764, 0, 59664985.546883, 0, -2151254201.10706, 0, 50104666029.4208, 0, -809383066629.104, 0, 9519886545589.94, 0, -84418993926334.3, 0, 579084677635030.0, 0, -3132572351397120.0, 0, 1.35579712441891e+16, 0, -4.74528993546618e+16, 0, 1.35328638900332e+17, 0, -3.15989038614568e+17, 0, 6.05475770764689e+17, 0, -9.51789563891462e+17, 0, 1.22372943928902e+18, 0, -1.27885238700474e+18, 0, 1.07520247922261e+18, 0, -7.15927504457983e+17, 0, 3.68666987345473e+17, 0, -1.41508540597252e+17, 0, 3.8093418421647e+16, 0, -6413687795481380.0, 0, 508064680269506.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0.318302669989846, 0, -438.621079246008, 0, 100517.330660544, 0, -9167180.55624157, 0, 444280857.672136, 0, -13249442466.5779, 0, 265591096716.403, 0, -3794158524520.04, 0, 40249698347616.8, 0, -326732845410066.0, 0, 2075613391631310.0, 0, -1.04948763698068e+16, 0, 4.27780286812778e+16, 0, -1.41891430518207e+17, 0, 3.85509256989945e+17, 0, -8.61413788032704e+17, 0, 1.58562658966504e+18, 0, -2.40246452979551e+18, 0, 2.98592020131728e+18, 0, -3.02414677572959e+18, 0, 2.46971986684583e+18, 0, -1.60058500081298e+18, 0, 8.03676401042457e+17, 0, -3.01281588023646e+17, 0, 7.93268011019706e+16, 0, -1.30808276102841e+16, 0, 1016082386017550.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, 17.0299506910936, 0, -8117.60982942129, 0, 1156759.40069253, 0, -77998633.875268, 0, 3039780092.41669, 0, -76602458328.9007, 0, 1340543020755.76, 0, -17107882360121.2, 0, 164914954221462.0, 0, -1232522289444610.0, 0, 7283619815241720.0, 0, -3.45468133529252e+16, 0, 1.33005231408762e+17, 0, -4.19099105236725e+17, 0, 1.08697378771988e+18, 0, -2.32822772595484e+18, 0, 4.1229032647117e+18, 0, -6.02844679041879e+18, 0, 7.25042924793611e+18, 0, -7.12322873481443e+18, 0, 5.65514866629779e+18, 0, -3.56969517141721e+18, 0, 1.74879005872459e+18, 0, -6.4062984574925e+17, 0, 1.65060240869067e+17, 0, -2.66685565639434e+16, 0, 2032074339052290.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [-0.318303189786061, 0, 472.680236832301, 0, -116752.018497578, 0, 11480615.1522619, 0, -600272163.675406, 0, 19328763670.3481, 0, -418789879524.208, 0, 6475135829566.61, 0, -74464062040016.0, 0, 656549148313605.0, 0, -4540555688863560.0, 0, 2.50615086722989e+16, 0, -1.11868763348812e+17, 0, 4.07890721748747e+17, 0, -1.22367216524624e+18, 0, 3.03526957770274e+18, 0, -6.2418850186629e+18, 0, 1.06479215024249e+19, 0, -1.5042301805013e+19, 0, 1.75243885893395e+19, 0, -1.67155706544469e+19, 0, 1.29104000989631e+19, 0, -7.94276200591596e+18, 0, 3.79871226369894e+18, 0, -1.36053169728224e+18, 0, 3.43187179151194e+17, 0, -5.43509107253023e+16, 0, 4063974456748670.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, -17.6665570712296, 0, 9062.94377754079, 0, -1390255.57547476, 0, 100959035.838048, 0, -4240279505.19801, 0, 115258506550.382, 0, -2178090239170.04, 0, 30057645300546.6, 0, -313837178873354.0, 0, 2545568228639430.0, 0, -1.63643671841106e+16, 0, 8.46678128221376e+16, 0, -3.5673371802394e+17, 0, 1.23484748546748e+18, 0, -3.53421866530349e+18, 0, 8.39851962400076e+18, 0, -1.66061638020015e+19, 0, 2.73234190960663e+19, 0, -3.73338008669975e+19, 0, 4.21705685906571e+19, 0, -3.90849172303651e+19, 0, 2.93894338863986e+19, 0, -1.76336603318392e+19, 0, 8.23774141311635e+18, 0, -2.88601144745233e+18, 0, 7.13014592899987e+17, 0, -1.10729407025107e+17, 0, 8127613040900100.0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0.318303655380866, 0, -508.012633987862, 0, 134877.354323777, 0, -14261032.2638341, 0, 802183064.840665, 0, -27809012914.4764, 0, 649298316684.972, 0, -10831152139865.8, 0, 134577065337832.0, 0, -1284199447014610.0, 0, 9631495852609580.0, 0, -5.77889751156575e+16, 0, 2.81197802827275e+17, 0, -1.1213303152743e+18, 0, 3.69327048284791e+18, 0, -1.01034295967563e+19, 0, 2.30382638587327e+19, 0, -4.38589408219724e+19, 0, 6.96869837504673e+19, 0, -9.21890396698927e+19, 0, 1.01053370407382e+20, 0, -9.10771375564794e+19, 0, 6.67192984425372e+19, 0, -3.90646327112827e+19, 0, 1.78353597928285e+19, 0, -6.11498050039835e+18, 0, 1.48032333380684e+18, 0, -2.25513966995032e+17, 0, 1.6254578140551e+16, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, 18.3031643824795, 0, -10078.9425199521, 0, 1660001.8330361, 0, -129480142.976816, 0, 5844589787.14795, 0, -170874552322.434, 0, 3476639929944.92, 0, -51719157814990.1, 0, 582981389193969.0, 0, -5113871835034820.0, 0, 3.56266404507426e+16, 0, -2.00241433679668e+17, 0, 9.19108180589675e+17, 0, -3.47742354365552e+18, 0, 1.09204803402975e+19, 0, -2.86046130203922e+19, 0, 6.26809417890034e+19, 0, -1.15037963753936e+20, 0, 1.76702457838252e+20, 0, -2.26541612613144e+20, 0, 2.41183936355213e+20, 0, -2.11536741520851e+20, 0, 1.51067147732568e+20, 0, -8.63640123022449e+19, 0, 3.85553626349308e+19, 0, -1.29425060452944e+19, 0, 3.07126231989207e+18, 0, -4.59138205398006e+17, 0, 3.25079055200343e+16, 0, 0, 0, 0, 0, 0, 0],
            [-0.318304074055755, 0, 544.618270709397, 0, -155034.667728608, 0, 17580931.3204242, 0, -1061134783.26846, 0, 39497794710.5482, 0, -991035576373.755, 0, 17784187870531.2, 0, -238011714333943.0, 0, 2450120588731770.0, 0, -1.98588721402469e+16, 0, 1.29039684339873e+17, 0, -6.81666158578025e+17, 0, 2.95947984539567e+18, 0, -1.06478639940162e+19, 0, 3.19435919820485e+19, 0, -8.0245394374259e+19, 0, 1.6921622378743e+20, 0, -2.99754453566305e+20, 0, 4.45580944490453e+20, 0, -5.54119892507359e+20, 0, 5.73427205835141e+20, 0, -4.89777148324307e+20, 0, 3.41187752600797e+20, 0, -1.90556989484488e+20, 0, 8.32228484687355e+19, 0, -2.73643755146068e+19, 0, 6.36781065434247e+18, 0, -9.34496888234675e+17, 0, 6.50133951282442e+16, 0, 0, 0, 0, 0, 0],
            [0, -18.9397725310158, 0, 11168.152535789, 0, -1970062.10731317, 0, 164640904.682601, 0, -7966790443.25252, 0, 249867518447.465, 0, -5458644249160.02, 0, 87286320898473.0, 0, -1058988452077060.0, 0, 1.00139434327989e+16, 0, -7.53430029705821e+16, 0, 4.58311784868482e+17, 0, -2.28239268864504e+18, 0, 9.39617502875237e+18, 0, -3.22154572414367e+19, 0, 9.24895385318666e+19, 0, -2.23166045624239e+20, 0, 4.53458401949083e+20, 0, -7.76190057390323e+20, 0, 1.11767178304383e+21, 0, -1.34938422586998e+21, 0, 1.3583502340153e+21, 0, -1.13058645740263e+21, 0, 7.68715121360717e+20, 0, -4.19655704008147e+20, 0, 1.79382242105443e+20, 0, -5.7798051883031e+19, 0, 1.3194302753096e+19, 0, -1.90143460727574e+18, 0, 1.30022121011842e+17, 0, 0, 0, 0, 0],
            [0.31830445190937, 0, -582.497146994147, 0, 177370.381259718, 0, -21520939.5928458, 0, 1390406418.69493, 0, -55430869225.3044, 0, 1490754437498.72, 0, -28701118401074.2, 0, 412578577015442.0, 0, -4568026859242870.0, 0, 3.98860871551785e+16, 0, -2.79720611218135e+17, 0, 1.59825870975e+18, 0, -7.52411023359229e+18, 0, 2.94395741679444e+19, 0, -9.63723071612709e+19, 0, 2.65218143699869e+20, 0, -6.15533017998625e+20, 0, 1.20664012258461e+21, 0, -1.99790768518988e+21, 0, 2.78938649893817e+21, 0, -3.27210262941644e+21, 0, 3.20638386624634e+21, 0, -2.60228255811297e+21, 0, 1.72793407449168e+21, 0, -9.22505212014335e+20, 0, 3.86116434892878e+20, 0, -1.21959908156241e+20, 0, 2.73221872168202e+19, 0, -3.8677506404936e+18, 0, 2.6003521255296e+17, 0, 0, 0, 0],
            [0, 19.5763814352058, 0, -12333.1203041797, 0, 2324793.17733787, 0, -207681523.842183, 0, 10747518858.833, 0, -360725814789.193, 0, 8440059128080.49, 0, -144686727909951.0, 0, 1884119081827380.0, 0, -1.91497015451227e+16, 0, 1.55112582515494e+17, 0, -1.01773473112933e+18, 0, 5.47880530257955e+18, 0, -2.44439005807395e+19, 0, 9.10926639868446e+19, 0, -2.85227782289991e+20, 0, 7.53584765709351e+20, 0, -1.68448359393855e+21, 0, 3.18939010804281e+21, 0, -5.1133541813156e+21, 0, 6.92797133590442e+21, 0, -7.90233718270383e+21, 0, 7.54314003803547e+21, 0, -5.97310626508637e+21, 0, 3.87540823151437e+21, 0, -2.02433088799104e+21, 0, 8.30005044785875e+20, 0, -2.57105939798991e+20, 0, 5.6543975482109e+19, 0, -7.86526368482872e+18, 0, 5.20052954024194e+17, 0, 0, 0],
            [-0.318304794080792, 0, 621.649262839786, 0, -202036.010422931, 0, 26170397.8834503, 0, -1805757453.95807, 0, 76925267538.6137, 0, -2212184208913.47, 0, 45580718590250.0, 0, -701943066289850.0, 0, 8336147395089270.0, 0, -7.81842876739425e+16, 0, 5.89935988812475e+17, 0, -3.63366369920727e+18, 0, 1.84813725993527e+19, 0, -7.83258172067805e+19, 0, 2.78551814296297e+20, 0, -8.35655442888892e+20, 0, 2.12265419985146e+21, 0, -4.57549905301316e+21, 0, 8.3764826191009e+21, 0, -1.30157653004491e+22, 0, 1.71275982408929e+22, 0, -1.9010547730378e+22, 0, 1.76880748447865e+22, 0, -1.36737599863952e+22, 0, 8.67307061994211e+21, 0, -4.43464696856769e+21, 0, 1.78191614739792e+21, 0, -5.41517374663783e+20, 0, 1.16952028284919e+20, 0, -1.59900513248307e+19, 0, 1.0400720851159e+18, 0, 0],
            [0, -20.2129910236934, 0, 13576.3923042474, 0, -2728854.85315373, 0, 260020883.864791, 0, -14358931031.2001, 0, 514571873863.554, 0, -12864296846588.8, 0, 235845442187462.0, 0, -3287962929319320.0, 0, 3.58214908615316e+16, 0, -3.11476391967413e+17, 0, 2.19757059154874e+18, 0, -1.27459094309827e+19, 0, 6.14055066888654e+19, 0, -2.47739458020595e+20, 0, 8.42314157270022e+20, 0, -2.42484378608037e+21, 0, 5.92966001470073e+21, 0, -1.23401032738367e+22, 0, 2.1865797029079e+22, 0, -3.29586891804166e+22, 0, 4.2156462905184e+22, 0, -4.5563045766209e+22, 0, 4.13481479154959e+22, 0, -3.12220708749663e+22, 0, 1.93699278918418e+22, 0, -9.69902049736637e+21, 0, 3.82082625653827e+21, 0, -1.13954467300264e+21, 0, 2.41761961601379e+20, 0, -3.24991489365788e+19, 0, 2.08007865697509e+18, 0],
            [0.318305104925165, 0, -662.074618244344, 0, 229188.16368225, 0, -31627966.5881506, 0, 2325785114.46436, 0, -105642328310.337, 0, 3241298709521.69, 0, -71308571609477.2, 0, 1173620241072650.0, 0, -1.49118807100995e+16, 0, 1.49825159345158e+17, 0, -1.21287033755604e+18, 0, 8.0286742996916e+18, 0, -4.39724315490801e+19, 0, 2.01133159122644e+20, 0, -7.74015881313348e+20, 0, 2.52023316193762e+21, 0, -6.97219584193793e+21, 0, 1.64344616274251e+22, 0, -3.30559441553046e+22, 0, 5.67460374666062e+22, 0, -8.30429816584481e+22, 0, 1.03320919040162e+23, 0, -1.08811402660654e+23, 0, 9.63675454414834e+22, 0, -7.1115315166613e+22, 0, 4.31733248183435e+22, 0, -2.11793668920176e+22, 0, 8.18293720827952e+21, 0, -2.39597193515262e+21, 0, 4.99499233938598e+20, 0, -6.60363873530669e+19, 0, 4.16003035408705e+18],
        ]
        assert num_spherical < 65
        self.num_spherical = num_spherical
        num_spherical += 1
        coefs = torch.tensor(coefs[1:num_spherical])[:, :num_spherical].T
        self.register_buffer("coefs", coefs)

    def forward(self, angle):
        n = len(angle)
        angle = torch.cat([angle, angle + torch.pi / 2])
        angle = angle.view(-1, 1)
        zero_order = torch.ones_like(angle)
        higher_order = angle.cos().repeat(1, self.num_spherical)
        cos = torch.cat([zero_order, higher_order], dim=-1).cumprod(dim=-1)
        sph = cos.mm(self.coefs)
        sph = sph.view(2 * n, -1)
        sph = torch.cat([sph[:n], sph[n:]], dim=1)
        return sph

def azimuth(x, y):
    return torch.arctan2(y, x)

def azimuth4(x, y):
    x_ = torch.stack([x, y, -x, -y], dim=-1)
    y_ = torch.stack([y, -x, -y, x], dim=-1)
    return torch.atan2(y_, x_)

class SinusoidalEmbedding(nn.Module):
    def __init__(self, n_channels: int, spacing: float, max_coord: float):
        super().__init__()
        self.spacing = spacing
        max_seq_len = max_coord / spacing
        div = math.ceil(max_seq_len * 4 / torch.pi)
        div = math.log(div) / (n_channels - 1)
        div = torch.exp(torch.arange(n_channels) * -div)
        self.register_buffer('div', div.unsqueeze(0))

    def forward(self, coords: torch.Tensor):
        # Create sinusoidal position embeddings
        # [same as those from the transformer](../../transformers/positional_encoding.html)
        #
        # \begin{align}
        # PE^{(1)}_{t,i} &= sin\Bigg(\frac{t}{10000^{\frac{i}{d - 1}}}\Bigg) \\
        # PE^{(2)}_{t,i} &= cos\Bigg(\frac{t}{10000^{\frac{i}{d - 1}}}\Bigg)
        # \end{align}
        #
        # where $d$ is `half_dim`
        n = len(coords)
        coords = coords.flatten() / self.spacing
        emb = coords.unsqueeze(1) * self.div
        emb = torch.cat((emb.sin(), emb.cos()), dim=1)
        emb = emb.unflatten(dim=0, sizes=(n, -1)).flatten(1)
        return emb

class EmbAngle(torch.nn.Module):
    def __init__(self, angle_type, angle_args, change_basis, get_dim=False):
        super(EmbAngle, self).__init__()
        self.angle_type = angle_type
        self.change_basis = change_basis
        match angle_type:
            case "azi":
                self.dim = 1
            case "azi4":
                self.dim = 4
            case "sph" | "sph4":
                if not get_dim:
                    self.angle_emb = SphericalHarmonicsEmbedding(angle_args["num_spherical"])
                self.dim = 2 * angle_args["num_spherical"]
                if angle_type == "sph4":
                    self.dim *= 4
            case "null":
                self.dim = 0
            case _:
                raise ValueError(f"Invalid angle_type: {angle_type}")
    
    def forward(self, coords, basis=None):
        if self.change_basis:
            assert basis is not None
            coords = change_basis(coords, basis)
        else:
            assert basis is None
        x, y = coords[:, 0], coords[:, 1]
        match self.angle_type:
            case "azi" | "sph": 
                angle = azimuth(x, y).unsqueeze(1)
                if self.angle_type == "azi":
                    return angle
                return self.angle_emb(angle)
            case "azi4" | "sph4":
                angle = azimuth4(x, y)
                if self.angle_type == "azi4":
                    return angle
                return self.angle_emb(angle)
            case "null":
                return coords[:, :0]
            case _:
                raise ValueError(f"Invalid angle_type: {self.angle_type}")            

class EmbDist(torch.nn.Module):
    def __init__(self, dist_type, dist_args, get_dim=False):
        super(EmbDist, self).__init__()
        self.dist_type = dist_type
        match dist_type:
            case "identity":
                self.dim = 1
            case "sine":
                self.dim = 2 * dist_args["dim"] + 1 
                self.dist_fn = SinusoidalEmbedding(n_channels=dist_args["dim"],
                                                   spacing=dist_args["spacing"],
                                                   max_coord=dist_args["max_coord"])
            case _:
                raise ValueError(f"Invalid dist_type: {dist_type}")

    def forward(self, dist):
        match self.dist_type:
            case "identity":
                return dist
            case "sine":
                return torch.cat([dist, self.dist_fn(dist)], dim=1)
            case _:
                raise ValueError(f"Invalid dist_type: {self.dist_type}")

class EmbCoords(torch.nn.Module):
    def __init__(self, coords_type, coords_args, change_basis, get_dim=False):
        super(EmbCoords, self).__init__()
        self.coords_type = coords_type
        self.change_basis = change_basis
        match coords_type:
            case "identity":
                self.dim = 2
            case "sine":
                self.dim = 2 + 4 * coords_args["dim"]
                if not get_dim:
                    self.coord_fn = SinusoidalEmbedding(n_channels=coords_args["dim"],
                                                        spacing=coords_args["spacing"],
                                                        max_coord=coords_args["max_coord"])
            case _:
                raise ValueError(f"Invalid dist_type: {coords_type}")

    def forward(self, coords, basis=None):
        if self.change_basis:
            assert basis is not None
            coords = change_basis(coords=coords, basis=basis)
        else:
            assert basis is None
        match self.coords_type:
            case "identity":
                return coords
            case "sine":
                return torch.cat([coords, self.coord_fn(coords)], dim=-1)

class MLP(torch.nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, activation, norm):
        '''
        3 layer MLP

        Args:
            input_dim: # input layer nodes
            hidden_dim: # hidden layer nodes
            output_dim: # output layer nodes
            activation: activation function
            layer_norm: bool; if True, apply LayerNorm to output
        '''
        super(MLP, self).__init__()
        self.lin1 = torch.nn.Linear(input_dim, hidden_dim)
        self.lin2 = torch.nn.Linear(hidden_dim, output_dim)

        self.activation = activation
        self.prenorm = self.preActnorm = self.postActnorm = self.postnorm = None
        self.norm = True
        match norm:
            case None | False:
                self.norm = False
            case "pre":
                self.prenorm = InstanceNorm(input_dim, affine=True)
            case "post":
                self.postnorm = InstanceNorm(output_dim, affine=True)
            case "preAct":
                self.preActnorm = InstanceNorm(hidden_dim, affine=True)
            case "postAct":
                self.postActnorm = InstanceNorm(hidden_dim, affine=True)
            case _:
                raise ValueError(f"Unknown norm {norm}")

    def forward(self, x, batch=None):
        if self.norm:
            assert batch is not None
            assert len(batch) == len(x)
        if self.prenorm:
            x = self.prenorm(x, batch=batch)        
        x = self.lin1(x)
        if self.preActnorm:
            x = self.preActnorm(x, batch=batch)
        x = self.activation(x)
        if self.postActnorm:
            x = self.postActnorm(x, batch=batch)
        x = self.lin2(x)
        if self.postnorm:
            x = self.postnorm(x, batch=batch)
        return x
    
    
class EdgeModel(torch.nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, norm):
        '''
        Update function for edges: 3-layer MLP with ReLU activation

        Args:
            input_dim: # input layer nodes
            hidden_dim: # hidden layer nodes
            output_dim: # output layer nodes
        '''

        super(EdgeModel, self).__init__()
        self.norm = norm
        self.edge_mlp = MLP(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, activation=F.relu, norm=norm)

    def forward(self, x_source, x_target, edge_index, edge_attr, batch):
        source_ind, target_ind = edge_index
        out = torch.cat([x_source[source_ind], x_target[target_ind], edge_attr], 1)
        if self.norm:
            assert len(batch.unique() == 1), "Batch not supported"
            batch = torch.zeros(len(out), device=out.device, dtype=torch.long)
        else:
            batch = None
        return self.edge_mlp(out, batch=batch)

class NodeModel(torch.nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, norm):
        '''
        Update node embeddings: 3 layer MLP with ReLU activation

        Args:
            input_dim: # input layer nodes
            hidden_dim: # hidden layer nodes
            output_dim: # output layer nodes
        '''

        # init the super class and the node update function
        super(NodeModel, self).__init__()
        self.node_mlp = MLP(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, activation=F.relu, norm=norm)

    def forward(self, x_target, edge_index, edge_attr, batch):
        # TODO: cat out versus add; sum versus mean aggregation
        if edge_attr is not None:
            _source_ind, target_ind = edge_index 
            out = scatter(src=edge_attr, index=target_ind, dim=0, dim_size=len(x_target), reduce="mean")
            out = torch.cat([x_target, out], dim=1)
        else:
            out = x_target
        return self.node_mlp(out, batch=batch)

class Processor(torch.nn.Module):
    def __init__(self, edge_input_dim, edge_hidden_dim, edge_output_dim, node_input_dim, node_hidden_dim, node_output_dim, independent, norm, mlp_norm, edge_norm):
        '''
        Graph Network layer; one step of message passing to update node and edge embeddings

        Args:
            edge_input_dim: # input layer nodes for edge update function
            edge_hidden_dim: # hidden layer nodes for edge update function
            edge_output_dim: # output layer nodes for edge update function
            node_input_dim: # input layer nodes for node update function
            node_hidden_dim: # hidden layer nodes for node update function
            node_output_dim: # output layer nodes for node update function
        '''
        super(Processor, self).__init__()
        self.independent = independent
        if independent:
            node_update_dim = node_input_dim
        else:
            edge_mlp_norm = mlp_norm if edge_norm else None
            node_update_dim = node_input_dim + edge_output_dim
            self.edge_model = EdgeModel(node_input_dim * 2 + edge_input_dim, edge_hidden_dim, edge_output_dim, norm=edge_mlp_norm)
        self.node_model = NodeModel(node_update_dim, node_hidden_dim, node_output_dim, norm=mlp_norm)
        if norm:
            self.norm = InstanceNorm(node_output_dim, affine=True)
        else:
            self.norm = None

    def forward(self, x_source, x_target, edge_index, edge_attr, batch):
        if not self.independent:
            edge_out = self.edge_model(x_source=x_source, x_target=x_target, edge_index=edge_index, edge_attr=edge_attr, batch=batch)
            edge_attr = edge_attr + edge_out
        x_out = self.node_model(x_target=x_target, edge_index=edge_index, edge_attr=edge_attr, batch=batch)
        x_target = x_target + x_out
        if self.norm:
            assert batch is not None
            assert len(batch) == len(x_target)
            x_target = self.norm(x_target, batch=batch)
        return x_target, edge_attr

class GNN(torch.nn.Module):
    def __init__(self, hparams: Dict, field: str):
        super().__init__()
        self.hparams = hparams

        # determine whether to use inlet coordinate system
        use_inlet_coords = field in ["turbulent_viscosity", "pressure"]
        self.pre_emb = True

        # angle, coordinate, and distance embeddings
        self.canonical_coords = self.hparams["canonical_coords"] or (self.hparams["inlet_coords"] and not use_inlet_coords)
        self.inlet_coords = self.hparams["inlet_coords"] and use_inlet_coords
        num_systems = self.canonical_coords + self.inlet_coords
        assert num_systems > 0
        ang_args = dict(num_spherical=hparams["ang_basis"])
        dist_args = dict(dim=hparams["dist_basis"],
                         spacing=hparams["coord_spacing"],
                         max_coord=hparams["coord_max"])
        coord_args = dict(dim=hparams["coord_basis"],
                          spacing=hparams["coord_spacing"],
                          max_coord=hparams["coord_max"])
        self.angle_fn = nn.ModuleDict()
        self.coord_fn = nn.ModuleDict()
        self.dist_fn = EmbDist(dist_type=self.hparams["dist"],
                               dist_args=dist_args)
        dist_dim = self.dist_fn.dim
        if self.canonical_coords:
            self.angle_fn[CANONICAL_COORDS] = EmbAngle(angle_type=self.hparams["angles"],
                                                       angle_args=ang_args,
                                                       change_basis=False)
            self.coord_fn[CANONICAL_COORDS] = EmbCoords(coords_type=self.hparams["coords"],
                                                        coords_args=coord_args,
                                                        change_basis=False)
            coords_dim = self.coord_fn[CANONICAL_COORDS].dim
            angle_dim = self.angle_fn[CANONICAL_COORDS].dim

        if self.inlet_coords:
            self.angle_fn[INLET_COORDS] = EmbAngle(angle_type=self.hparams["angles"],
                                                   angle_args=ang_args,
                                                   change_basis=True)
            self.coord_fn[INLET_COORDS] = EmbCoords(coords_type=self.hparams["coords"],
                                                    coords_args=coord_args,
                                                    change_basis=True)
            coords_dim = self.coord_fn[INLET_COORDS].dim
            angle_dim = self.angle_fn[INLET_COORDS].dim
        
        # change of basis for inlets and normals
        if self.inlet_coords:
            self.cob_fn = EmbCoords(coords_type="identity", 
                                    change_basis=True, 
                                    coords_args=dict())

        # compute number of dimensions in input angle, distance, and coordinate embeddings
        self.edge_dim = dist_dim + num_systems * (angle_dim + coords_dim)

        # radius graphs
        self.surf_spacing = hparams["surf_spacing"]
        self.surf_radius = hparams["surf_radius"]
        self.vol_radius = hparams["vol_radius"]
        self.surf_max_num_neighbors = hparams["surf_max_num_neighbors"]
        self.vol_max_num_neighbors = hparams["vol_max_num_neighbors"]
        self.s2v_max_num_neighbors = hparams["s2v_max_num_neighbors"]
        surface_radius_fn = get_radius_fn(manual=hparams["manual_radius"])
        self.radius_graph_surface = surface_radius_fn(r=self.surf_radius, max_num_neighbors=self.surf_max_num_neighbors)
        volume_manual = hparams["manual_radius"] and (self.vol_radius == 0)
        volume_radius_fn = get_radius_fn(manual=volume_manual)
        self.radius_graph_volume = volume_radius_fn(r=self.vol_radius, max_num_neighbors=self.vol_max_num_neighbors)

        # model size
        self.num_layers = hparams["num_layers"]
        hidden_dim = hparams["hidden_dim"]

        self.node_embedding = nn.ModuleDict()
        self.edge_embedding = nn.ModuleDict()
        self.processor = nn.ModuleDict()

        proc_norm = False
        mlp_norm = None
        match hparams["norm_type"]:
            case "proc":
                proc_norm = True
            case "mlp_pre":
                mlp_norm = "pre"
            case "mlp_post":
                mlp_norm = "post"
            case "mlp_preAct":
                mlp_norm = "preAct"
            case "mlp_postAct":
                mlp_norm = "postAct"
            case _:
                raise ValueError(f"Unknown norm type: {hparams['norm_type']}")

        # define coordinate systems for which polar and cartesian coordinates will be included as node features
        self.distance_systems = [NOSE, CLOSEST]
        self.coordinate_systems = [NOSE]
        self.angle_systems = [NOSE]
        if hparams["tail_coords"]:
            self.coordinate_systems.append(TAIL)
            self.angle_systems.append(TAIL)
            self.distance_systems.append(TAIL)
        if hparams["closest_coords"]:
            self.coordinate_systems.append(CLOSEST)
            self.angle_systems.append(CLOSEST)

        # compute number of dimensions in angle, distance, and coordinate embeddings
        self.node_dim = sum([len(self.angle_systems) * angle_dim * num_systems, 
                             len(self.coordinate_systems) * coords_dim * num_systems,
                             len(self.distance_systems) * dist_dim, 
                             2, 2 * num_systems])  # for inlet and normal vectors

        self.independence_map = {
            VOLUME: self.radius_graph_volume.r == 0,
            SURFACE: self.radius_graph_surface.r == 0,
            SURFACE2VOLUME: self.s2v_max_num_neighbors == 0
        }

        # init encoders and processors for each graph
        for graph_name in VOLUME, SURFACE, SURFACE2VOLUME:
            surf2vol = graph_name == SURFACE2VOLUME
            surf = graph_name == SURFACE
            independent = self.independence_map[graph_name]
            
            # node embedding
            if not surf2vol and not (surf and self.independence_map[SURFACE2VOLUME]):
                self.node_embedding[graph_name] = MLP(input_dim=self.node_dim,
                                                      hidden_dim=hidden_dim,
                                                      output_dim=hidden_dim,
                                                      activation=F.relu,
                                                      norm=None)                    

            # edge embedding
            if not independent:
                self.edge_embedding[graph_name] = MLP(input_dim=self.edge_dim,
                                                      hidden_dim=hidden_dim,
                                                      output_dim=hidden_dim,
                                                      activation=F.relu,
                                                      norm=None)

            # processor
            if not (surf and self.independence_map[SURFACE2VOLUME]):
                self.processor[graph_name] = torch.nn.ModuleList([
                    Processor(
                        edge_input_dim=hidden_dim,
                        edge_hidden_dim=hidden_dim,
                        edge_output_dim=hidden_dim,
                        node_input_dim=hidden_dim,
                        node_hidden_dim=hidden_dim,
                        node_output_dim=hidden_dim,
                        independent=independent,
                        norm=proc_norm if i < self.num_layers - 1 else False,
                        mlp_norm=mlp_norm,
                        edge_norm=hparams["edge_norm"],
                        ) for i in range(self.num_layers)
                        ])
            
        # decoder
        self.mlp_out = nn.Sequential(nn.Linear(hidden_dim + self.node_dim, 1024),
                                     nn.ReLU(),
                                     nn.Linear(1024, 512),
                                     nn.ReLU(),
                                     nn.Linear(512, hparams["target_dim"]))

    def forward(self, batch_: Dict[str, Data]):
        
        # get edges for each graph
        batch = {graph_name: graph.clone() for graph_name, graph in batch_.items()}
        if not self.pre_emb:
            batch = self.preprocess(batch)
        x = dict()

        # encode nodes and edges
        edge_index = dict()
        edge_attr = dict()
        batch_idx = dict()
        for graph_name in VOLUME, SURFACE, SURFACE2VOLUME:
            surf2vol = graph_name == SURFACE2VOLUME
            surf = graph_name == SURFACE
            independent = self.independence_map[graph_name]
            if not surf2vol and not (surf and self.independence_map[SURFACE2VOLUME]):
                node_embedding = self.node_embedding[graph_name]
                x[graph_name] = node_embedding(batch[graph_name].x)
            else:
                x[graph_name] = None
            if not independent:
                edge_embedding = self.edge_embedding[graph_name]
                edge_attr[graph_name] = edge_embedding(batch[graph_name].edge_attr)
                edge_index[graph_name] = batch[graph_name].edge_index
            else:
                edge_attr[graph_name] = edge_index[graph_name] = None
            batch_idx[graph_name] = batch[graph_name].batch

        # surface graph message passing to encode geometry of airfoil
        if not self.independence_map[SURFACE2VOLUME]:
            for processor in self.processor[SURFACE]:
                x[SURFACE], edge_attr[SURFACE] = processor(x_source=x[SURFACE],
                                                           x_target=x[SURFACE], 
                                                           edge_index=edge_index[SURFACE], 
                                                           edge_attr=edge_attr[SURFACE], 
                                                           batch=batch_idx[SURFACE])

        # surface to volume message passing
        for i in range(len(self.processor[VOLUME])):
            vol_processor = self.processor[VOLUME][i]
            s2v_processor = self.processor[SURFACE2VOLUME][i]

            x[VOLUME], edge_attr[VOLUME] = vol_processor(x_source=x[VOLUME],
                                                         x_target=x[VOLUME],
                                                         edge_index=edge_index[VOLUME],
                                                         edge_attr=edge_attr[VOLUME],
                                                         batch=batch_idx[VOLUME])
            x[VOLUME], edge_attr[SURFACE2VOLUME] = s2v_processor(x_source=x[SURFACE],
                                                                 x_target=x[VOLUME],
                                                                 edge_index=edge_index[SURFACE2VOLUME],
                                                                 edge_attr=edge_attr[SURFACE2VOLUME],
                                                                 batch=batch_idx[VOLUME])

        return self.mlp_out(torch.cat([x[VOLUME], batch[VOLUME].x], dim=-1))
    
    def preprocess(self, batch: Dict):
        for graph_name, graph in batch.items():
            assert len(graph) == 1, "Batch not supported"
            if graph_name == SURFACE2VOLUME:
                continue

            # add inlet vel and surface normal as node feature
            # surface normal can be computed with respect to canonical and inlet velocity coordinate systems
            features = [graph.x]
            if self.canonical_coords:
                features.append(graph.surface_normal)
            if self.inlet_coords:
                cob_surf_normals = self.cob_fn(coords=graph.surface_normal, basis=graph.inlet_vel[0])
                features.append(cob_surf_normals)
            graph.x = torch.cat(features, dim=-1)

        # compute edges and embed coordinates
        batch = self.get_edges(batch)
        batch[VOLUME] = self.coords_emb(batch=batch, graph_name=VOLUME)
        if not self.independence_map[SURFACE2VOLUME]:
            batch[SURFACE] = self.coords_emb(batch=batch, graph_name=SURFACE)

        return batch

    def coords_emb(self, batch: Data, graph_name: str):
        graph = batch[graph_name]
        assert len(graph) == 1, "Batch not supported"
        
        # embed distances
        distances = graph.dist
        emb_dists = []
        for distance_system in self.distance_systems:
            dist = distances[distance_system]
            emb_dist = self.dist_fn(dist)
            emb_dists.append(emb_dist) 
        emb_dists = torch.cat(emb_dists, dim=-1)
        
        # embed angles
        coords = graph.coords
        emb_angles = []
        basis = graph.inlet_vel[0]
        for angle_system in self.angle_systems:
            coord = coords[angle_system]
            if self.canonical_coords:
                emb_angle_canonical = self.angle_fn[CANONICAL_COORDS](coord)
                emb_angles.append(emb_angle_canonical)
            if self.inlet_coords:
                emb_angle_inlet = self.angle_fn[INLET_COORDS](coord, basis)
                emb_angles.append(emb_angle_inlet)
        emb_angles = torch.cat(emb_angles, dim=-1)

        # embed coords
        emb_coords = []
        for coord_system in self.coordinate_systems:
            coord = coords[coord_system]
            if self.canonical_coords:
                emb_coord_canonical = self.coord_fn[CANONICAL_COORDS](coord)
                emb_coords.append(emb_coord_canonical)
            if self.inlet_coords:
                emb_coord_inlet = self.coord_fn[INLET_COORDS](coord, basis)
                emb_coords.append(emb_coord_inlet)
        emb_coords = torch.cat(emb_coords, dim=-1)

        graph.x = torch.cat([graph.x, emb_dists, emb_angles, emb_coords], dim=-1)

        return graph

    def get_edges(self, batch: Dict[str, Data]):
        volume_graph, surface_graph = batch[VOLUME], batch[SURFACE]
        basis = volume_graph.inlet_vel[0]
        surf2vol = Data()
        if not self.independence_map[SURFACE2VOLUME]:
            with torch.no_grad():
                # for each volume node, find closest surface nodes
                assert len(volume_graph) == 1, f"Not implemented for batched graphs: {len(volume_graph)}"
                dists = (surface_graph.pos.unsqueeze(0) - volume_graph.pos.unsqueeze(1)).norm(dim=-1)
                surface_source = dists.neg().topk(k=self.s2v_max_num_neighbors * self.surf_spacing, dim=1).indices[:, ::self.surf_spacing].flatten()
                volume_target = torch.arange(len(dists), device=dists.device).repeat_interleave(self.s2v_max_num_neighbors)

            # features for s2v edges
            surf2vol_displacement = surface_graph.pos[surface_source] - volume_graph.pos[volume_target]
            surf2vol_attr = self.get_edge_attr(displacement=surf2vol_displacement, basis=basis)

            # construct s2v graph
            surf2vol_indices = torch.stack([surface_source, volume_target])
            surf2vol = Data(edge_index=surf2vol_indices,
                            edge_attr=surf2vol_attr,
                            batch=surface_graph.batch)

        # construct surface graph
        surface_graph = self.radius_graph_surface(surface_graph)
        if not self.independence_map[SURFACE]:
            source_ind, target_ind = surface_graph.edge_index
            surf_displacement = (surface_graph.pos[source_ind] - surface_graph.pos[target_ind]) / self.surf_radius
            surface_graph.edge_attr = self.get_edge_attr(displacement=surf_displacement, basis=basis)
        
        # construct volume graph
        volume_graph = self.radius_graph_volume(volume_graph)
        if not self.independence_map[VOLUME]:
            source_ind, target_ind = volume_graph.edge_index
            vol_displacement = (volume_graph.pos[source_ind] - volume_graph.pos[target_ind]) / self.vol_radius
            volume_graph.edge_attr = self.get_edge_attr(displacement=vol_displacement, basis=basis)
            
        return {SURFACE2VOLUME: surf2vol, SURFACE: surface_graph, VOLUME: volume_graph}

    def get_edge_attr(self, displacement: torch.Tensor, basis: torch.Tensor):
        dist = displacement.norm(dim=1).unsqueeze(1)
        dist = self.dist_fn(dist)
        edge_attr = [dist]
        if self.canonical_coords:
            canonical_displacement = self.coord_fn[CANONICAL_COORDS](coords=displacement)
            canonical_angles = self.angle_fn[CANONICAL_COORDS](coords=displacement)
            edge_attr.extend([canonical_displacement, canonical_angles])
        if self.inlet_coords:
            inlet_displacement = self.coord_fn[INLET_COORDS](coords=displacement, basis=basis)
            inlet_angles = self.angle_fn[INLET_COORDS](coords=displacement, basis=basis)
            edge_attr.extend([inlet_displacement, inlet_angles])
        edge_attr = torch.cat(edge_attr, dim=1)
        return edge_attr

class LogScale(nn.Module):
    def __init__(self):
        super().__init__()

    def scale(self, x):
        numpy = False
        if isinstance(x, np.ndarray):
            numpy = True
            x = torch.from_numpy(x)
        x = torch.sign(x) * torch.log(torch.abs(x) + 1)
        if numpy:
            x = x.numpy()
        return x
    
    def unscale(self, x):
        numpy = False
        if isinstance(x, np.ndarray):
            numpy = True
            x = torch.from_numpy(x)
        neg_mask = x < 0
        x = torch.exp(torch.sign(x) * x)
        x[neg_mask] = 1 - x[neg_mask]
        x[~neg_mask] = x[~neg_mask] - 1
        if numpy:
            x = x.numpy()
        return x

class AugmentedSimulator():
    def __init__(self, 
                 benchmark: AirfRANSBenchmark, 
                 writer: SummaryWriter=None,
                 model=GNN,
                 **kwargs):
        self.hparams = kwargs
        self.name = "AirfRANSSubmission"
        chunk_sizes = benchmark.train_dataset.get_simulations_sizes()

        self.data_path = benchmark.evaluation.data_path

        # ('x-velocity', 'y-velocity', 'pressure', 'turbulent_viscosity')
        self.surf_loss_weight = {'x-velocity': self.hparams["vel_surf_weight"], 
                                 'y-velocity': self.hparams["vel_surf_weight"], 
                                 'pressure': self.hparams["pres_surf_weight"], 
                                 'turbulent_viscosity': self.hparams["visc_surf_weight"]}
        self.target_names = benchmark.train_dataset._attr_y
        self.target_indices_map = {target_name: i for i, target_name in enumerate(self.target_names)}
        self.xvelocity_idx = self.target_indices_map['x-velocity']
        self.yvelocity_idx = self.target_indices_map['y-velocity']
        self.pressure_idx = self.target_indices_map['pressure']
        self.viscosity_idx = self.target_indices_map['turbulent_viscosity']

        # ('x-position', 'y-position', 'x-inlet_velocity', 'y-inlet_velocity', 'distance_function', 'x-normals', 'y-normals')
        self.input_names = benchmark.train_dataset._attr_x
        self.input_indices_map = {input_name: i for i, input_name in enumerate(self.input_names)}
        self.inlet_inds = [i for i, name in enumerate(self.input_names) if "inlet_velocity" in name]
        self.normal_inds = [i for i, name in enumerate(self.input_names) if "normal" in name]
        scalerParams={"chunk_sizes": chunk_sizes, 
                      "no_norm_x": self.normal_inds}
        self.scaler = StandardScalerIterative(**scalerParams)
        self.logscale_press = self.hparams["logscale_pressure"]
        self.clamp_pressure = self.hparams["clamp_pressure"]
        if self.logscale_press:
            self.log_scale = LogScale()
            self.pressure_scaler = StandardScalerIterative(chunk_sizes=chunk_sizes)
            self.log_pressure_scaler = StandardScalerIterative(chunk_sizes=chunk_sizes)

        self.ensemble_size = self.hparams["ensemble_size"]
        use_cuda = torch.cuda.is_available()
        self.device = 'cuda:0' if use_cuda else 'cpu'
        if use_cuda:
            print('Using GPU')
        else:
            print('Using CPU')

        self.model = torch.nn.ModuleList([
            torch.nn.ModuleDict({
                target: model(self.hparams, field=target) for target in self.target_names
                }) for _ in range(self.ensemble_size)])
        print(f"# params: {self.count_parameters()}")
        self.summary()
        self.writer = writer
        self.ckpt_path = None
        if writer is not None:
            self.ckpt_path = os.path.dirname(writer.log_dir)
            if self.logscale_press:
                self.pressure_scaler_path = os.path.join(self.ckpt_path, "pressure_scaler")
                self.log_pressure_scaler_path = os.path.join(self.ckpt_path, "log_pressure_scaler")
        self.epoch_num = -1
        self.criterion = self.hparams["criterion"]
        assert self.criterion in ["MSE", "MSE_weighted"], f"Invalid criterion: {self.criterion}"
        self.train_criterion = nn.MSELoss(reduction='none')
        self.eval_criterion = nn.MSELoss(reduction='none')

    def summary(self):
        """summary of the model
        """
        print(self.hparams)
        print(self.model)
        print(f"Number of parameters: {self.count_parameters()}")
        print(f"Node dim: { {var: model.node_dim for var, model in self.model[0].items()} }")
        print(f"Edge dim: { {var: model.edge_dim for var, model in self.model[0].items()} }")
        independence_map = list(self.model[0].values())[0].independence_map
        surf = independence_map[SURFACE]
        vol = independence_map[VOLUME]
        s2v = independence_map[SURFACE2VOLUME]
        if surf and vol and s2v:
            mode = "MLP"
        elif surf and s2v and not vol:
            mode = "GNN"
        elif not surf and not s2v and vol:
            mode = "s2v message passing"
        elif not surf and not s2v and not vol:
            mode = "s2v message passing w/ GNN"
        else:
            raise ValueError(f"Invalid independence map: {independence_map}")
        print(f"Mode: {mode}")

    def count_parameters(self):
        """
        count the number of parameters in the model
        """
        return sum(p.numel() for p in self.model.parameters() if p.requires_grad)


    def log(self, tag: str, value: float, step: int):
        if self.writer is not None:
            self.writer.add_scalar(tag=tag, scalar_value=value, global_step=step)
    
    def process_dataset(self, dataset: AirfRANSDataSet, training: bool) -> DataLoader:
        
        # x, y coords of all nodes across all simulations of shape (nb_nodes, )
        coord_x=dataset.data['x-position']
        coord_y=dataset.data['y-position']

        # indicates whether or not the node is on the surface of airfoil
        surf_bool=dataset.extra_data['surface']  
        position = np.stack([coord_x,coord_y],axis=1)

        # (nb_nodes, nb_features) and (nb_nodes, nb_targets)
        nodes_features,node_labels=dataset.extract_data() 

        # get inlet velocity 
        inlet_vels = nodes_features[:, self.inlet_inds]

        # get normals
        surface_normals = nodes_features[:, self.normal_inds]


        pressure = node_labels[:, self.pressure_idx:self.pressure_idx + 1].copy()
        if training:
            print("Normalize train data")
            fmt = lambda stats: ", ".join([f"{x:.2e}" for x in stats])
            nodes_features, node_labels = self.scaler.fit_transform(nodes_features, node_labels)
            if self.ckpt_path is not None:
                self.scaler.save(path=self.ckpt_path)
            print(f"Scaler x: \nmean - {fmt(self.scaler._m_x)}\nstd - {fmt(self.scaler._std_x)}\n\n")
            print(f"Scaler y: \nmean - {fmt(self.scaler._m_y)}\nstd - {fmt(self.scaler._std_y)}\n\n")
            if self.logscale_press:

                log_pressure = self.log_scale.scale(pressure)
                _, log_pressure_norm = self.log_pressure_scaler.fit_transform(np.zeros_like(log_pressure), log_pressure)
                print(f"Log Pressure Scaler x (0's): \nmean - {fmt(self.log_pressure_scaler._m_x)}\nstd - {fmt(self.log_pressure_scaler._std_x)}\n\n")
                print(f"Log Pressure Scaler y: \nmean - {fmt(self.log_pressure_scaler._m_y)}\nstd - {fmt(self.log_pressure_scaler._std_y)}\n\n")
                _, pressure_norm = self.pressure_scaler.fit_transform(np.zeros_like(pressure), pressure)
                self.pressure_scaler._m_x = np.array([pressure_norm.min(), pressure_norm.max()])
                print(f"Pressure Scaler x: \nmin, max - {fmt(self.pressure_scaler._m_x)}\n1's - {fmt(self.pressure_scaler._std_x)}\n\n")
                print(f"Pressure Scaler y: \nmean - {fmt(self.pressure_scaler._m_y)}\nstd - {fmt(self.pressure_scaler._std_y)}\n\n")
                node_labels[:, self.pressure_idx:self.pressure_idx + 1] = log_pressure_norm
                if self.ckpt_path is not None:
                    self.log_pressure_scaler.save(path=self.log_pressure_scaler_path)
                    self.pressure_scaler.save(path=self.pressure_scaler_path)
            print("Transform done")
        else:
            print("Normalize not train data")
            nodes_features, node_labels = self.scaler.transform(nodes_features, node_labels)
            print("Transform done")

        torchDataset=[]

        # get nb nodes in each simulation
        nb_nodes_in_simulations = dataset.get_simulations_sizes() 
        start_index = 0

        # check alive
        t = dt.datetime.now()

        # extract simulation graphs
        for nb_nodes_in_simulation in tqdm(nb_nodes_in_simulations, desc="Extracting graphs"):
            #still alive?
            if dt.datetime.now() - t > dt.timedelta(seconds=60):
                print("Still alive - index : ", end_index)
                t = dt.datetime.now()
            end_index = start_index+nb_nodes_in_simulation
            simulation_positions = torch.tensor(position[start_index:end_index,:], dtype = torch.float)
            simulation_features = torch.tensor(nodes_features[start_index:end_index,:], dtype = torch.float)
            inlet_vel = torch.tensor(inlet_vels[start_index:end_index,:], dtype=torch.float)
            surface_normal = torch.tensor(surface_normals[start_index:end_index,:], dtype = torch.float) 
            simulation_labels = torch.tensor(node_labels[start_index:end_index,:], dtype = torch.float) 
            simulation_surface = torch.tensor(surf_bool[start_index:end_index], dtype=torch.bool)
            
            # cartesian coordinates and distances stored for later embedding
            coords = dict()
            distances = dict()

            # inlet vectors
            simulation_features = simulation_features[:, self.inlet_inds]
            
            # nose coordinate system
            surf_coords = simulation_positions[simulation_surface]
            leftmost = surf_coords[surf_coords[:, 0].argmin()]
            leftmost_displacement = simulation_positions - leftmost
            leftmost_dist = leftmost_displacement.norm(dim=-1).unsqueeze(-1)
            distances[NOSE] = leftmost_dist
            coords[NOSE] = leftmost_displacement

            # tail coordinate system
            if self.hparams["tail_coords"]:
                rightmost = surf_coords[surf_coords[:,0].argmax()]
                rightmost_displacement = simulation_positions - rightmost
                rightmost_dist = rightmost_displacement.norm(dim=-1).unsqueeze(-1)
                distances[TAIL] = rightmost_dist
                coords[TAIL] = rightmost_displacement

            with torch.no_grad():
                closest_surf_ind = (simulation_positions.unsqueeze(0).to(self.device) - surf_coords.unsqueeze(1).to(self.device)).norm(dim=-1).argmin(dim=0).cpu()
            closest_displacement = simulation_positions - surf_coords[closest_surf_ind]
            closest_dist = closest_displacement.norm(dim=-1).unsqueeze(-1)
            distances[CLOSEST] = closest_dist
            if self.hparams["closest_coords"]:
                coords[CLOSEST] = closest_displacement
            
            sampleData=Data(pos=simulation_positions,
                            x=simulation_features, 
                            y=simulation_labels,
                            dist=distances,
                            coords=coords,
                            surf=simulation_surface,
                            inlet_vel=inlet_vel,
                            surface_normal=surface_normal)
            # xsurfacePos, ysurfacePos = sampleData.pos[sampleData.surf].T
            torchDataset.append(sampleData)
            start_index += nb_nodes_in_simulation
        
        return DataLoader(dataset=torchDataset,batch_size=1)

    def _post_process(self, data):
        try:
            processed = self.scaler.inverse_transform(data)
        except TypeError:
            processed = self.scaler.inverse_transform(data.cpu())
        return processed

    def init_losses(self, add_log):
        num_vars = len(self.target_names)
        if add_log:
            num_vars += 1
        return dict(loss_var=torch.zeros(num_vars),
                    loss=0,
                    loss_var_surf=torch.zeros(num_vars), 
                    loss_var_vol=torch.zeros(num_vars), 
                    loss_surf=0, 
                    loss_vol=0)
    
    def compute_losses(self, out, targets, loss_criterion, losses, surface):
        num_vars = len(self.target_names)
        loss_per_var = loss_criterion(out, targets).mean(dim = 0)
        total_loss = loss_per_var[:num_vars].mean()
        # compute loss on surface and away from surface of airfoil
        loss_surf_var = torch.zeros_like(loss_per_var)
        loss_vol_var = torch.zeros_like(loss_per_var)
        if surface.any():
            loss_surf_var = loss_criterion(out[surface, :], targets[surface, :]).mean(dim = 0)
        if not surface.all():
            loss_vol_var = loss_criterion(out[~surface, :], targets[~surface, :]).mean(dim = 0)
        loss_surf = loss_surf_var[:num_vars].mean()
        loss_vol = loss_vol_var[:num_vars].mean()
        losses["loss_var"] += loss_per_var.detach().cpu()
        losses["loss"] += total_loss.detach().cpu()
        losses["loss_var_surf"] += loss_surf_var.detach().cpu()
        losses["loss_var_vol"] += loss_vol_var.detach().cpu()
        losses["loss_surf"] += loss_surf.detach().cpu()
        losses["loss_vol"] += loss_vol.detach().cpu()

        return dict(total_loss=total_loss, loss_surf=loss_surf, loss_vol=loss_vol)

    def log_losses(self, dataset_name: str, losses: dict, iterNum: int, member_idx: int=None):
        if member_idx is None:
            member_idx = ""
        averaged_losses = dict()
        var_names_suffix = [f"_{var_name}" for var_name in self.target_names]
        if self.logscale_press:
            var_names_suffix.append("_log_pressure")
        for loss_name, loss in losses.items():
            loss = (loss / iterNum).tolist()
            if isinstance(loss, float):
                loss = [loss]
                var_names = [""]
            else:
                var_names = var_names_suffix
            assert len(loss) in [len(var_names), len(var_names) - 1], [len(loss), len(var_names)]
            for var_loss, var_name in zip(loss, var_names):
                tag = f"{dataset_name}/{loss_name}{var_name}{member_idx}"
                averaged_losses[tag] = var_loss
                self.log(tag=tag, value=var_loss, step=self.epoch_num)

        return averaged_losses

    def log2normalized_pressure(self, log_pressure, predictions):
        log_mean = self.log_pressure_scaler._m_y.item()
        log_std = self.log_pressure_scaler._std_y.item()
        mean = self.pressure_scaler._m_y.item()
        std = self.pressure_scaler._std_y.item()

        log_pressure = log_pressure * log_std + log_mean
        pressure = self.log_scale.unscale(log_pressure)
        pressure = (pressure - mean) / std

        if self.clamp_pressure and predictions:
            min_, max_ = self.pressure_scaler._m_x
            pressure = torch.clamp(pressure, min=min_, max=max_)

        return pressure

    def epoch(self, loader: DataLoader, pbar: tqdm, mode: str, dataset_name: str, member_idx: int=None):
        assert mode in ["train", "validate", "predict"], f"Mode should be one of ['train', 'validate', 'predict']; got {mode}"
        return_preds = False
        if mode == "train":
            assert member_idx is not None
            member_indices = [member_idx]
            self.model.train()
            training = True
            loss_criterion = self.train_criterion
        else:
            assert member_idx is None
            member_indices = list(range(self.ensemble_size))
            self.model.eval()
            training = False
            loss_criterion = self.eval_criterion
            if mode == "predict":
                return_preds = True
                predictions = []
        
        losses = self.init_losses(add_log=training and self.logscale_press)

        with torch.set_grad_enabled(training):
            for i, data in enumerate(loader):
                data_clone = {name: graph.clone().to(self.device) for name, graph in data.items()}
                input_type = inputs = None
                ensemble_out = []
                targets = data_clone[VOLUME].y
                surf = data_clone[VOLUME].surf
                for member_idx in member_indices:
                    out = []
                    for target_idx, target in enumerate(self.target_names):
                        model = self.model[member_idx][target]
                        preprocess = False
                        match target:
                            case "x-velocity" | "y-velocity":
                                if input_type != "vel":
                                    input_type = "vel"
                                    preprocess = True
                            case "turbulent_viscosity" | "pressure":
                                if input_type != "presVisc":
                                    input_type = "presVisc"
                                    preprocess = True
                            case _:
                                raise ValueError(target)
                        if preprocess:
                            inputs = {name: graph.clone() for name, graph in data_clone.items()}
                            inputs = model.preprocess(inputs)
                        pred = model(inputs)

                        if training:
                            self.optimizer[member_idx][target].zero_grad()
                            if self.surf_loss_weight[target] > 0:
                                loss_surf = loss_criterion(pred[surf], targets[surf, target_idx].unsqueeze(1)).mean()
                                loss_vol = loss_criterion(pred[~surf], targets[~surf, target_idx].unsqueeze(1)).mean()
                                loss = self.surf_loss_weight[target] * loss_surf + loss_vol
                            else:
                                loss = loss_criterion(pred, targets[:, target_idx].unsqueeze(1)).mean()
                            loss.backward()
                            if i == 0:
                                for param_name, param in model.named_parameters():
                                    if param.grad is None:
                                        raise ValueError(param_name, param.shape)

                            self.optimizer[member_idx][target].step()
                            self.lr_scheduler[member_idx][target].step()

                        if target == "pressure" and self.logscale_press:
                            log_pred = pred.clone().detach()
                            log_target = targets[:, target_idx:target_idx + 1].clone().detach()
                            pred = self.log2normalized_pressure(pred, predictions=True)
                            if training:
                                targets[:, target_idx] = self.log2normalized_pressure(targets[:, target_idx], predictions=False)

                        out.append(pred.detach())

                    if self.logscale_press and training:
                        out.append(log_pred)

                    out = torch.cat(out, dim=1)
                    ensemble_out.append(out)

                if self.logscale_press and training:
                    targets = torch.cat([targets, log_target], dim=1)

                if not training and self.ensemble_size > 1:
                    out = torch.stack(ensemble_out).mean(dim=0)

                data_clone = data_clone[VOLUME]

                with torch.no_grad():
                    step_losses = self.compute_losses(out=out,
                                                      targets=targets,
                                                      loss_criterion=loss_criterion,
                                                      losses=losses,
                                                      surface=data_clone.surf)
                total_loss = step_losses["total_loss"]
                if training:
                    pbar.set_description("Epoch {} - Loss {:.3f}".format(self.epoch_num, step_losses["total_loss"].item()))
                    if i % self.hparams["log_every"] == 0:
                        step = self.lr_scheduler[member_idx][target]._step_count
                        self.log(tag=f"train/loss{member_idx}/step", value=total_loss.item(), step=step)
                        self.log(tag=f"train/lr{member_idx}/step", value=self.lr_scheduler[member_idx][target].get_last_lr()[0], step=step)

                else:
                    pbar.set_description("{} - Loss {:.3f}".format(dataset_name, total_loss.item()))
                    if return_preds:
                        out = out.cpu().data.numpy()
                        prediction = self._post_process(out)
                        predictions.append(prediction)
                pbar.update()

        if not training:
            member_idx = None
        averaged_losses = self.log_losses(dataset_name=dataset_name, 
                                          losses=losses, 
                                          iterNum=len(loader),
                                          member_idx=member_idx)

        if return_preds:
            return averaged_losses, predictions
        else:
            return averaged_losses

    def prep_loader(self, loader: DataLoader, train: bool, subsample: bool):
        loader_sampled = []
        # subsampling hparams['subsampling'] nodes from each graph
        for data in loader:
            loader_sample = dict()
            if subsample:
                idx = random.sample(range(len(data.y)), self.hparams['subsampling'])
                idx = torch.tensor(idx)
            else:
                idx  = None
            surface_idx = torch.where(data.surf)[0]
            indices = {VOLUME: idx, SURFACE: surface_idx}
            for loader_name, loader_idx in indices.items():
                data_sampled: Data = data.clone()
                if loader_idx is not None:
                    data_sampled.pos = data_sampled.pos[loader_idx]
                    data_sampled.x = data_sampled.x[loader_idx]
                    data_sampled.y = data_sampled.y[loader_idx]
                    data_sampled.surf = data_sampled.surf[loader_idx]
                    data_sampled.batch = data_sampled.batch[loader_idx]
                    data_sampled.inlet_vel = data_sampled.inlet_vel[loader_idx]
                    data_sampled.surface_normal = data_sampled.surface_normal[loader_idx]
                    data_sampled.dist = {coord_system: dist[loader_idx] for coord_system, dist in data_sampled.dist.items()}
                    data_sampled.coords = {coord_system: coords[loader_idx] for coord_system, coords in data_sampled.coords.items()}
                loader_sample[loader_name] = data_sampled
            loader_sampled.append(loader_sample)
        if train:
            return DataLoader(loader_sampled, batch_size=self.hparams['batch_size'], shuffle=True)
        else:
            return DataLoader(loader_sampled, batch_size=1, shuffle=False)

    def global_train(self, train_loader: DataLoader, valid_loaders: Dict[str, DataLoader]):
        self.model.to(self.device)
        self.optimizer = [{target: 
                           torch.optim.Adam(self.model[member_idx][target].parameters(), 
                                            lr=self.hparams['lr'])
                                            for target in self.target_names} for member_idx in range(self.ensemble_size)]
        steps_per_epoch = len(train_loader) // self.hparams['batch_size'] + 1
        num_steps = steps_per_epoch * self.hparams['nb_epochs']
        self.lr_scheduler = [{target: 
                              torch.optim.lr_scheduler.OneCycleLR(self.optimizer[member_idx][target], 
                                                                  max_lr=self.hparams['lr'], 
                                                                  total_steps=num_steps) 
                                                                  for target in self.target_names} for member_idx in range(self.ensemble_size)]
        pbar_train = tqdm(total=num_steps * self.ensemble_size, position=0)

        for epoch in range(self.hparams['nb_epochs']):
            self.epoch_num = epoch
            for member_idx in range(self.ensemble_size):
                self.log(tag=f"train/lr{member_idx}/epoch", 
                         value=self.lr_scheduler[member_idx][self.target_names[0]].get_last_lr()[0], 
                         step=epoch)
                train_loader_sampled = self.prep_loader(loader=train_loader, train=True, subsample=True)
                self.epoch(loader=train_loader_sampled, 
                           pbar=pbar_train, 
                           mode="train", 
                           dataset_name="train",
                           member_idx=member_idx)
            if epoch % self.hparams["eval_every"] == 0:
                for dataset_name, valid_loader in valid_loaders.items():
                    valid_loader_subsampled = self.prep_loader(loader=valid_loader, train=False, subsample=True)
                    self.validate(loader=valid_loader_subsampled, dataset_name=f"{dataset_name}_subsampled")

        pbar_train.close()
        if self.ckpt_path is not None:
            torch.save(self.model.state_dict(), os.path.join(self.ckpt_path, "ckpt.pt"))

    def train(self, 
              train_dataset: Union[AirfRANSDataSet, DataLoader], 
              valid_datasets: Dict[str, Union[AirfRANSDataSet, DataLoader]]={},
              **kwargs):
        if isinstance(train_dataset, DataLoader):
            train_loader = train_dataset
            valid_loaders = valid_datasets
        elif isinstance(train_dataset, AirfRANSDataSet):
            train_loader = self.process_dataset(dataset=train_dataset, training=True)
            valid_loaders = {dataset_name: self.process_dataset(dataset=dataset, training=False) for dataset_name, dataset in valid_datasets.items()}
        else:
            raise TypeError(f"Expected DataLoader or AirfRANSDataSet, got {type(train_dataset)}")
        print("Start training")
        self.global_train(train_loader=train_loader, valid_loaders=valid_loaders)
        print("Training done")

    def validate(self, loader: DataLoader, dataset_name: str):
        pbar = tqdm(total=len(loader), position=0)
        outputs = self.epoch(loader=loader, pbar=pbar, mode="validate", dataset_name=dataset_name)
        pbar.close()
        return outputs

    def predict(self, dataset: AirfRANSDataSet, **kwargs):
        test_loader = self.process_dataset(dataset=dataset, training=False)
        test_loader = self.prep_loader(loader=test_loader, train=False, subsample=False)
        pbar = tqdm(total=len(test_loader), position=0)
        averaged_losses, predictions = self.epoch(loader=test_loader, pbar=pbar, mode="predict", dataset_name=dataset.name)
        pbar.close()
        print(f"Results for test: {averaged_losses}")
        predictions = np.vstack(predictions)
        predictions = dataset.reconstruct_output(predictions)
        return predictions

    def restore(self, path):
        self.model.load_state_dict(torch.load(os.path.join(path, "ckpt.pt")))
        self.model.to(self.device)
        self.scaler.load(path)
        if self.logscale_press:
            pressure_path = os.path.join(path, "pressure_scaler")
            self.pressure_scaler.load(pressure_path)
            log_pressure_path = os.path.join(path, "log_pressure_scaler")
            self.log_pressure_scaler.load(log_pressure_path)
