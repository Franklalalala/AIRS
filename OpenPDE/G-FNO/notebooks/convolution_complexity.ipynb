{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Comparison of physical convolution and Fourier convolution from: https://stackoverflow.com/a/60584560/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from timeit import default_timer\n",
    "import pandas as pd\n",
    "import warnings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def conv2d_pyt(f, g):\n",
    "    assert len(f.size()) == 3\n",
    "    assert len(g.size()) == 3\n",
    "\n",
    "    f_new = f.unsqueeze(0)\n",
    "    g_new = g.unsqueeze(0)\n",
    "\n",
    "    pad_y = (g.size(1) - 1) // 2\n",
    "    pad_x = (g.size(2) - 1) // 2\n",
    "\n",
    "    fcg = F.conv2d(f_new, g_new, bias=None, padding=(pad_y, pad_x))\n",
    "    return fcg[0, 0, :, :]\n",
    "\n",
    "def conv2d_fft(f_new, F_g):\n",
    "    assert len(f.size()) == 3\n",
    "    assert len(g.size()) == 3\n",
    "\n",
    "    # take fft of both f and g\n",
    "    F_f = torch.fft.rfft2(f_new, dim=[-1,-2])\n",
    "\n",
    "    # complex multiply\n",
    "    FxG = F_f * F_g\n",
    "\n",
    "    # sum over channels\n",
    "    FxG = FxG.sum(0)\n",
    "\n",
    "    # inverse fft\n",
    "    fcg = torch.fft.irfft2(FxG, f_new.shape[1:], dim=[-1, -2])\n",
    "\n",
    "    f_pad_y = (f_new.size(1) - f.size(1)) // 2\n",
    "    f_pad_x = (f_new.size(2) - f.size(2)) // 2\n",
    "\n",
    "    # crop center before returning\n",
    "    return fcg[f_pad_y:-f_pad_y, f_pad_x:-f_pad_x]\n",
    "\n",
    "# function for pre-processing the input to conv2d_fft so that the output is\n",
    "# identical to conv2d_pyt\n",
    "# also transforms the kernel, since we directly learn the transform of the\n",
    "# kernel\n",
    "def fft_preprocess(f, g):\n",
    "    assert len(f.size()) == 3\n",
    "    assert len(g.size()) == 3\n",
    "\n",
    "    device = f.device\n",
    "\n",
    "    size_y = f.size(1) + g.size(1) - 1\n",
    "    size_x = f.size(2) + g.size(2) - 1\n",
    "\n",
    "    f_new = torch.zeros((f.shape[0], size_y, size_x)).to(device)\n",
    "    g_new = torch.zeros((f.shape[0], size_y, size_x)).to(device)\n",
    "\n",
    "    # copy f to center\n",
    "    f_pad_y = (f_new.size(1) - f.size(1)) // 2\n",
    "    f_pad_x = (f_new.size(2) - f.size(2)) // 2\n",
    "    f_new[:, f_pad_y:-f_pad_y, f_pad_x:-f_pad_x] = f\n",
    "\n",
    "    # anchor of g is 0,0 (flip g and wrap circular)\n",
    "    g_center_y = g.size(1) // 2\n",
    "    g_center_x = g.size(2) // 2\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        g_y, g_x = torch.meshgrid(torch.arange(g.size(1)), torch.arange(g.size(2)))\n",
    "    g_new_y = (g_y.flip(0) - g_center_y) % g_new.size(1)\n",
    "    g_new_x = (g_x.flip(1) - g_center_x) % g_new.size(2)\n",
    "    g_new[:, g_new_y, g_new_x] = g[:, g_y, g_x]\n",
    "\n",
    "    # transform the kernel\n",
    "    F_g = torch.fft.rfft2(g_new, dim=[-1,-2])\n",
    "\n",
    "    return f_new, F_g"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The output for these convolutions is identical:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average difference: 4.117644039070001e-06\n",
      "L2 relative loss: 4.2855637616412423e-07\n"
     ]
    }
   ],
   "source": [
    "# calculate f*g\n",
    "torch.manual_seed(1)\n",
    "num_channels = 20\n",
    "H = W = 64\n",
    "kernel_size = 3\n",
    "f = torch.randn(num_channels, H, W).cuda()\n",
    "g = torch.randn(num_channels, kernel_size, kernel_size).cuda()\n",
    "\n",
    "fcg_pyt = conv2d_pyt(f, g)\n",
    "f_new, F_g = fft_preprocess(f, g)\n",
    "fcg_fft = conv2d_fft(f_new, F_g)\n",
    "\n",
    "loss = lambda x, y: ((x - y).norm() / x.norm()).item()\n",
    "\n",
    "avg_diff = torch.mean(torch.abs(fcg_pyt - fcg_fft)).item()\n",
    "\n",
    "print('Average difference:', avg_diff)\n",
    "print('L2 relative loss:', loss(fcg_pyt, fcg_fft))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Time complexity analysis:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def time_conv(f, g):\n",
    "\n",
    "    start = default_timer()\n",
    "    fcg_pyt = conv2d_pyt(f, g)\n",
    "    time_pyt = (default_timer() - start) * 1000\n",
    "\n",
    "    f_new, F_g = fft_preprocess(f, g)\n",
    "    start = default_timer()\n",
    "    fcg_fft = conv2d_fft(f_new, F_g)\n",
    "    time_fft = (default_timer() - start) * 1000\n",
    "\n",
    "    diff = loss(fcg_pyt, fcg_fft)\n",
    "\n",
    "    return {\"Physical Convolution\":time_pyt, \"Fourier Convolution\":time_fft, \"diff\":diff}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "({'Physical Convolution': ['0.131(0.029)'],\n  'Fourier Convolution': ['0.143(0.025)']},\n 4.6969438471933245e-07)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "times = {\"Physical Convolution\":[], \"Fourier Convolution\":[]}\n",
    "n = 10000\n",
    "max_diff = 0\n",
    "for _ in range(n):\n",
    "\n",
    "    f = torch.randn(num_channels, H, W).cuda()\n",
    "    g = torch.randn(num_channels, kernel_size, kernel_size).cuda()\n",
    "    trial = time_conv(f, g)\n",
    "    times[\"Physical Convolution\"].append(trial[\"Physical Convolution\"])\n",
    "    times[\"Fourier Convolution\"].append(trial[\"Fourier Convolution\"])\n",
    "    if trial[\"diff\"] > max_diff:\n",
    "        max_diff = trial[\"diff\"]\n",
    "\n",
    "for conv in times.keys():\n",
    "    times[conv] = np.array(times[conv])\n",
    "    mu = times[conv].mean()\n",
    "    sigma = times[conv].std()\n",
    "    times[conv] = [f\"{mu.round(3)}({sigma.round(3)})\"]\n",
    "\n",
    "times, max_diff"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|           | Physical Convolution   | Fourier Convolution   |\n",
      "|:----------|:-----------------------|:----------------------|\n",
      "| Time (ms) | 0.131(0.029)           | 0.143(0.025)          |\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(times)\n",
    "df.index = [\"Time (ms)\"]\n",
    "print(df.to_markdown())"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "gfno",
   "language": "python",
   "display_name": "GFNO"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
