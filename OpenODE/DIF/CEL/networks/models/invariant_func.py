import torch
from CEL.networks.models.meta_model import ModelClass
from torch.autograd import Function
from itertools import chain
from copy import deepcopy
from tqdm import tqdm

class InvariantFunc(torch.nn.Module, ModelClass):
    def __init__(
            self,
            y_channels: int,
            W_channels: int,
            dfunc_hidden_channels: int,
            hyper_hidden_channels: int,
            depth_enc: int,
            num_envs: int,
    ):
        super().__init__()
        self.dfunc_hidden_channels = dfunc_hidden_channels
        self.hyper_hidden_channels = hyper_hidden_channels
        self.depth_enc = depth_enc
        self.derivative_func = torch.nn.Sequential(
            *([
                torch.nn.Linear(y_channels, dfunc_hidden_channels // 4),
                torch.nn.LayerNorm(dfunc_hidden_channels // 4),
                torch.nn.ReLU(),
                torch.nn.Linear(dfunc_hidden_channels // 4, dfunc_hidden_channels // 2),
                torch.nn.LayerNorm(dfunc_hidden_channels // 2),
                torch.nn.ReLU(),
                torch.nn.Linear(dfunc_hidden_channels // 2, dfunc_hidden_channels),
            ] + list(chain(*[[
                torch.nn.LayerNorm(dfunc_hidden_channels),
                torch.nn.ReLU(),
                torch.nn.Linear(dfunc_hidden_channels, dfunc_hidden_channels)
            ] for _ in range(depth_enc)]))
              + [torch.nn.LayerNorm(dfunc_hidden_channels),
                torch.nn.ReLU(),
                torch.nn.Linear(dfunc_hidden_channels, y_channels)])
        )
        self.hyper_network = HyperNetwork(self.derivative_func, hyper_hidden_channels, W_channels, num_envs)

    def forward(self, y, envs, W, **kwargs):
        if kwargs.get("forecast") is None:
            # print('Fit hyper_network')
            self.updated_derivative_funcs = self.hyper_network(self.derivative_func, envs, W)
        dys = []
        for i, updated_dfunc in tqdm(enumerate(self.updated_derivative_funcs), disable=True):
            dy = updated_dfunc(y[i:i+1])
            dys.append(dy)
        return torch.cat(dys)

class HyperNetwork(torch.nn.Module):
    def __init__(self, main_func, hidden_channels, W_channels, num_envs):
        super().__init__()
        params_main_func = serialize_parameters(main_func)
        num_param_main_func = params_main_func.numel()
        self.env_embeddings = torch.nn.Embedding(num_envs, hidden_channels)
        self.adaptation_embedding = torch.nn.Parameter(torch.randn(1, hidden_channels))
        self.system_param_encoder = torch.nn.Sequential(
            *[
                torch.nn.Linear(W_channels, hidden_channels),
                torch.nn.LayerNorm(hidden_channels),
                torch.nn.ReLU(),
            ])
        self.hyper_mlp = torch.nn.Sequential(
            *[
                torch.nn.Linear(hidden_channels * 2, hidden_channels),
                torch.nn.LayerNorm(hidden_channels),
                torch.nn.ReLU(),
                torch.nn.Linear(hidden_channels, hidden_channels),
                torch.nn.LayerNorm(hidden_channels),
                torch.nn.ReLU(),
                torch.nn.Linear(hidden_channels, num_param_main_func),
            ]
        )
        # If the main model's parameter is generated by a hypernetwork, then the VC-dimension of the main model is restricted by the hypernetwork.
        # Therefore, the main model parameters should not be generated from a low-dimensional space.
        # Consider that the main model/func has VC-dimension d, then the function of the function (hypernetwork) should have VC-dimension at least d.
        # Generally, it should be much larger than d. Maybe d x num_envs? Let's try it first.
        # self.frame_main_func = deepcopy(main_func) # Deep copy here or use the keyword deep_copy in the deserialize_parameters function

    def forward(self, main_func, envs, W):
        params_main_func = serialize_parameters(main_func)

        # Maybe also concatenate the low-dimension projected system parameters?
        if envs is None:
            params_env_sp = self.hyper_mlp(torch.cat([self.adaptation_embedding.repeat(W.shape[0], 1), self.system_param_encoder(W)], dim=-1))
        else:
            params_env_sp = self.hyper_mlp(torch.cat([self.env_embeddings(envs), self.system_param_encoder(W)], dim=-1))

        # --- Combine the main function parameters with the hypernetwork generated parameters ---
        assert params_main_func.numel() == params_env_sp.shape[1]
        updated_main_funcs = []
        for i in tqdm(range(params_env_sp.shape[0]), disable=True):
            updated_main_func = deserialize_parameters(main_func, params_main_func + params_env_sp[i], deep_copy=True)
            updated_main_funcs.append(updated_main_func)

        return updated_main_funcs

    def init_adaptation(self):
        # Initialize the adaptation embeddings
        self.adaptation_embedding.data = torch.nn.init.normal_(self.adaptation_embedding)

def serialize_parameters(model, requires_grad=True):
    params = []
    for param in model.parameters():
        # Flatten and append to the list
        params.append(param.view(-1))
    # Concatenate all parameters into a single vector
    serialized_vector = torch.cat(params)
    return serialized_vector

def deserialize_parameters(model, param_vector, deep_copy=False):
    if deep_copy:
        model = deepcopy(model)
    set_requires_grad(model, False)
    pointer = 0  # Initialize pointer to track the position in the parameter vector
    for param in model.parameters():
        num_param = param.numel()  # Number of elements in the parameter
        # Extract the part of the parameter vector and reshape it
        param_flat = param_vector[pointer:pointer + num_param]
        # param.data = param_flat.view(param.size())#.clone()
        param.copy_(param_flat.view(param.size()))#.clone()
        pointer += num_param
    return model

def set_requires_grad(module, tf=False):
    module.requires_grad = tf
    for param in module.parameters():
        param.requires_grad = tf